# ASRInput  
**A local, real-time speech input system with VAD-based segmentation.**  

ASRInput is a fully local speech-to-text solution designed for Windows. It leverages **Voice Activity Detection (VAD)** for smart segmentation and transcribes speech in real-time with a floating UI. This tool is lightweight, efficient, and requires no internet connection.

---

## ğŸš€ Features
### ğŸ™ **Real-time Speech Recognition**
- Runs entirely **offline**, ensuring **privacy**.
- Uses **VAD-based segmentation** for improved transcription accuracy.
- **Low-latency** processing optimized for real-time input.

### ğŸ–¥ **Floating UI for Seamless Input**
- **Non-intrusive overlay window** for easy transcription.
- Allows **manual text correction** before confirming input.
- Outputs to the **active application** without switching focus.

### âš¡ **Optimized for Performance**
- **Hardware adaptive** â€“ Works on CPU, but utilizes **GPU acceleration** if available.
- Efficient **audio buffer management** to maintain **low memory footprint**.

### âŒ¨ **Global Hotkey Support**
- **Quick toggle** for enabling/disabling recognition.
- Customizable hotkeys via `config.yaml`.

### ğŸ”§ **Adaptive Model Optimization**
- **Remembers corrections** for **personalized** transcription.
- Supports **custom ASR models** and fine-tuning.

---

## ğŸ“‚ Project Structure  
```
ASRInput/
â”œâ”€â”€ src/                    
â”‚   â”œâ”€â”€ asr_core.py          # Speech recognition core
â”‚   â”œâ”€â”€ config.py            # Configuration handler
â”‚   â”œâ”€â”€ config.yaml          # User settings
â”‚   â”œâ”€â”€ main.py              # Application entry point
â”‚   â”œâ”€â”€ window.py            # Floating UI implementation
â”‚   â”œâ”€â”€ worker_thread.py     # Background audio processing thread
â”œâ”€â”€ models/                  # ASR models (if applicable)
â”œâ”€â”€ config/                  
â”‚   â””â”€â”€ settings.yaml        # Customizable settings
â”œâ”€â”€ tests/                   # Unit tests
â”œâ”€â”€ requirements.txt         # Project dependencies
â””â”€â”€ README.md                # Documentation
```

---

## ğŸ¯ How It Works
1. **Start ASRInput**  
   - Run `python src/main.py`  
   - The floating input window appears.

2. **Speak naturally**  
   - ASRInput listens in real-time and transcribes speech.

3. **Edit if needed**  
   - Modify recognized text before confirming.

4. **Insert text automatically**  
   - Press confirm, and the text will be **typed into the active window**.

---

## ğŸ’» System Requirements
- Windows 10/11  
- Python 3.9+  
- **Optional**: NVIDIA GPU (Recommended for better performance)  

### ğŸ”§ Installation
1. Clone the repository:
   ```sh
   git clone https://github.com/yourusername/ASRInput.git
   cd ASRInput
   ```
2. Create a virtual environment:
   ```sh
   python -m venv venv
   source venv/Scripts/activate  # Windows
   ```
3. Install dependencies:
   ```sh
   pip install -r requirements.txt
   ```

### â–¶ï¸ Run the application
```sh
python src/main.py
```

---

## ğŸ›  Configuration
Modify `config.yaml` to:
- Adjust hotkeys
- Select ASR model
- Optimize VAD parameters

---

## ğŸ“Œ Roadmap
- âœ… Initial release with **real-time speech input**
- â³ Future improvements:
  - ğŸ”¹ Custom **language models**
  - ğŸ”¹ Advanced **noise filtering**
  - ğŸ”¹ Multi-language support

---

## âš– License
This project is licensed under the **MIT License**.

---

Now, ASRInput is ready for use! ğŸš€ Let me know if you need refinements.